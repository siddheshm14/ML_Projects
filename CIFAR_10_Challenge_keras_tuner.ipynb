{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CIFAR_10-Challenge_keras_tuner.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8nzy9fLFrfX"
      },
      "source": [
        "# Lab 2: CIFAR-10 Challenge\n",
        "\n",
        "In this lab you will experiment with whatever ConvNet architecture/design you'd like on [CIFAR-10 image dataset](https://www.cs.toronto.edu/~kriz/cifar.html). \n",
        "\n",
        "## Part 1: Creating the network (50% of grade)\n",
        "\n",
        "**Goal:** After training, your model should achieve **at least 80%** accuracy on a **validation** set within 20 epochs. (Or as close as possible as long as there is demonstrated effort to achieve this goal.)\n",
        "\n",
        "**Data split** The training set should consist of 40000 images, the validation set should consist of 10000 images, and the test set should consist of the remaining 10000 images. **Please use the Keras `load_data()` function to import the data set.**\n",
        "\n",
        "**Implementation** All code should be in Keras/python. \n",
        "\n",
        "### Some things you can try:\n",
        "- Different number/type of layers\n",
        "- Different filter sizes \n",
        "- Adjust the number of filters used in any given layer\n",
        "- Try various pooling strategies\n",
        "- Consider using batch normalization\n",
        "- Explore different numbers of layers in your network\n",
        "- Check if adding regularization helps\n",
        "- Consider alternative optimizers\n",
        "- Try different activation functions\n",
        "\n",
        "\n",
        "### Tips for training\n",
        "When building/tuning your model, keep in mind the following points: \n",
        "\n",
        "- This is experimental, so be driven by results achieved on the validation set as opposed to what you have heard/read works well or doesn't\n",
        "- If the hyperparameters are working well, you should see improvement in the loss/accuracy within a few hundred iterations (usually within one epoch)\n",
        "- For hyperparameter tuning: start by testing a large range of hyperparameters for just a few training iterations to find the combinations of parameters that are working at all\n",
        "- Once you have found some sets of hyperparameters that seem to work, search more finely around these parameters. You may need to train for more epochs.\n",
        "- Prefer one validation to to cross-validation \n",
        "- Prefer random search to grid search for hyperparameters\n",
        "- You should use the validation set for hyperparameter search and for evaluating different architectures\n",
        "- The test set should only be used at the very end to evaluate your final model\n",
        "\n",
        "### What to provide\n",
        "\n",
        "The cell below should contain all the code necessary to run your final network on the cifar10 dataset as contained within Keras. All necessary hyperparameters should be visible either in the code or through comments. Your code should include 2 plots: one for training and validation loss per epoch and one for training and validation accuracy per epoch.  \n",
        "\n",
        "Your network should produce an accuracy of at least 80% on the validation set within 20 epochs. (Or as close as possible as long as there is demonstrated effort to achieve this goal.)\n",
        "\n",
        "You should also evaluate and report the accuracy on the test set. The test set should be used only once. That is, after you have decided on what to include in your network and tuned any hyperparameters for your final network, you should use this final network on the test set and calculate the accuracy.  \n",
        "\n",
        "**Please make sure that all code has been run and the output is visible in the notebook before submitting.**\n",
        "\n",
        "**Please note that I should be able to run the single code cell below and reproduce your results.**\n",
        "\n",
        "**All code should be in ONE code cell.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHAh8XWbFHLg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "679a4266-696b-45f9-873b-2357080c3eec"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "!pip install keras-tuner\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,Conv2D, MaxPool2D,Flatten\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from kerastuner import RandomSearch\n",
        "from kerastuner.engine.hyperparameters import HyperParameters\n",
        "\n",
        "(X_train,y_train),(X_test,y_test)=cifar10.load_data()\n",
        "X_train.shape\n",
        "X_train.shape\n",
        "X_train_1=X_train\n",
        "y_train_1=y_train\n",
        "X_train_1.shape\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42,stratify=y_train)\n",
        "\n",
        "\n",
        "# To convert pixel values in the range of 0 and 1 Just run one time\n",
        "X_train=X_train/255.0\n",
        "X_train_1=X_train_1/255.0\n",
        "X_test =X_test/255.0\n",
        "X_val=X_val/255.0\n",
        "\n",
        "y_cat_train=to_categorical(y_train,10) #10 for 10 classes\n",
        "y_cat_train_1=to_categorical(y_train_1,10) #10 for 10 classes\n",
        "\n",
        "y_cat_test=to_categorical(y_test)\n",
        "y_cat_val=to_categorical(y_val)\n",
        "\n",
        "# Building Model implemented \n",
        "\n",
        "def build_model(hp):  \n",
        "  model = keras.Sequential([\n",
        "                            # Convolutional LAYER 1\n",
        "    keras.layers.Conv2D(\n",
        "        filters=hp.Int('conv_1_filter', min_value=32, max_value=128, step=16),\n",
        "        kernel_size=hp.Choice('conv_1_kernel', values = [3,4]),\n",
        "        activation='relu',\n",
        "        padding='same',\n",
        "        input_shape=(32,32,3)\n",
        "    ),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    \n",
        "              # Convolutional LAYER 2\n",
        "    keras.layers.Conv2D(\n",
        "        filters=hp.Int('conv_2_filter', min_value=32, max_value=64, step=16),\n",
        "        kernel_size=hp.Choice('conv_2_kernel', values = [3,4]),\n",
        "        activation='relu',\n",
        "        padding='same'\n",
        "    ),\n",
        "    keras.layers.BatchNormalization(),\n",
        "\n",
        "    keras.layers.MaxPool2D(pool_size=2 ),\n",
        "          # Convolutional LAYER 3\n",
        "    keras.layers.Conv2D(\n",
        "        filters=hp.Int('conv_3_filter', min_value=32, max_value=64, step=16),\n",
        "        kernel_size=hp.Choice('conv_3_kernel', values = [3,4]),\n",
        "        activation='relu',\n",
        "        padding='same'\n",
        "    ),\n",
        "    keras.layers.BatchNormalization(),    \n",
        "    \n",
        "\n",
        "        # Convolutional LAYER 4\n",
        "    keras.layers.Conv2D(\n",
        "        filters=hp.Int('conv_4_filter', min_value=32, max_value=64, step=16),\n",
        "        kernel_size=hp.Choice('conv_4_kernel', values = [3,4]),\n",
        "        activation='relu',\n",
        "        padding='same'\n",
        "    ),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.MaxPool2D(pool_size=2 ),\n",
        "    \n",
        "              # Convolutional LAYER 5\n",
        "    keras.layers.Conv2D(\n",
        "        filters=hp.Int('conv_5_filter', min_value=32, max_value=64, step=16),\n",
        "        kernel_size=hp.Choice('conv_5_kernel', values = [3,4]),\n",
        "        activation='relu',\n",
        "        padding='same'\n",
        "    ),\n",
        "    keras.layers.BatchNormalization(),\n",
        "\n",
        "          # Convolutional LAYER 6\n",
        "    keras.layers.Conv2D(\n",
        "        filters=hp.Int('conv_6_filter', min_value=32, max_value=64, step=16),\n",
        "        kernel_size=hp.Choice('conv_6_kernel', values = [3,4]),\n",
        "        activation='relu',\n",
        "        padding='same'\n",
        "    ),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.MaxPool2D(pool_size=2 ),\n",
        "    keras.layers.Dropout(0.2),\n",
        "\n",
        "    keras.layers.Flatten(),\n",
        "    \n",
        "    #Added Dense Fully connected network Layer\n",
        "    keras.layers.Dense(\n",
        "        units=hp.Int('dense_1_units', min_value=64, max_value=256, step=16),\n",
        "        activation='relu'\n",
        "    ),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Dropout(0.5),\n",
        "    \n",
        "    \n",
        "    #As our Output is of 10 classes so the number of neuron in our last dense layer should be 10\n",
        "    keras.layers.Dense(10, activation='softmax')\n",
        "  ])\n",
        "  \n",
        "    \n",
        "  model.compile(optimizer=keras.optimizers.Adam(hp.Choice('learning_rate', values=[1e-2, 1e-3])),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "  \n",
        "  return model\n",
        "\n",
        "\n",
        "tuner_search1=RandomSearch(build_model,\n",
        "                          objective='val_accuracy',\n",
        "                          max_trials=2,\n",
        "                          directory='output55',\n",
        "                          project_name=\"LAB2_DAB300\")\n",
        "# Increment directory value by one number e.g., 'output 55' in next runs to enable new directory for each run and store model statistics \n",
        "\n",
        "\n",
        "tuner_search1.search(X_train_1,y_cat_train_1,epochs=10,validation_split=0.2)\n",
        "\n",
        "#Picking up the best model from the trail\n",
        "\n",
        "print(\"Selecting the best model from the trail\")\n",
        "\n",
        "model=tuner_search1.get_best_models(num_models=1)[0]\n",
        "model.summary()\n",
        "\n",
        "#Early Stopping is used to stop  training when a monitored metric has stopped improving\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "early_stop=EarlyStopping(monitor='val_loss',patience=2)\n",
        "\n",
        "#####Fitting The Model##################\n",
        "\n",
        "\n",
        "model1 =model.fit(X_train_1, y_cat_train_1,batch_size=96, epochs = 20, validation_split=0.2,callbacks=[early_stop])\n",
        "\n",
        "# loss and accuracy list for traning and validation\n",
        "\n",
        "metrics=pd.DataFrame(model1.history)\n",
        "metrics\n",
        "\n",
        "# Accuracy plot for traning and validation data\n",
        "print(metrics.columns)\n",
        "print(\"Training Accuracy vs Validation Accuracy\")\n",
        "print('\\n')\n",
        "metrics[['accuracy','val_accuracy']].plot()\n",
        "\n",
        "\n",
        "\n",
        "# Loss plot for traning and validation data\n",
        "print(metrics.columns)\n",
        "print('\\n')\n",
        "print(\"Training loss vs Validation loss\")\n",
        "print('\\n')\n",
        "metrics[['loss','val_loss']].plot()\n",
        "\n",
        "#########Evaluation of Test Accuracy ####################################\n",
        "\n",
        "\n",
        "\n",
        "test_loss,test_acc=model.evaluate(X_test,y_cat_test,verbose=0)\n",
        "\n",
        "print('\\n')\n",
        "\n",
        "print(\"Test Accuracy\",test_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras-tuner in /usr/local/lib/python3.6/dist-packages (1.0.1)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (0.8.7)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (0.16.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (0.22.2.post1)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (0.4.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (2.23.0)\n",
            "Requirement already satisfied: terminaltables in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (3.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (1.18.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (4.41.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->keras-tuner) (0.17.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner) (1.24.3)\n",
            "Epoch 1/10\n",
            "   1/1250 [..............................] - ETA: 0s - loss: 3.6040 - accuracy: 0.1250WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0073s vs `on_train_batch_end` time: 0.0132s). Check your callbacks.\n",
            "1250/1250 [==============================] - 19s 15ms/step - loss: 1.7037 - accuracy: 0.3877 - val_loss: 1.5525 - val_accuracy: 0.4565\n",
            "Epoch 2/10\n",
            "1250/1250 [==============================] - 19s 15ms/step - loss: 1.1787 - accuracy: 0.5849 - val_loss: 0.9560 - val_accuracy: 0.6538\n",
            "Epoch 3/10\n",
            "1250/1250 [==============================] - 19s 15ms/step - loss: 0.9676 - accuracy: 0.6658 - val_loss: 0.9227 - val_accuracy: 0.6778\n",
            "Epoch 4/10\n",
            "1250/1250 [==============================] - 19s 15ms/step - loss: 0.8553 - accuracy: 0.7059 - val_loss: 1.0256 - val_accuracy: 0.6624\n",
            "Epoch 5/10\n",
            "1250/1250 [==============================] - 19s 15ms/step - loss: 0.7810 - accuracy: 0.7335 - val_loss: 0.7892 - val_accuracy: 0.7305\n",
            "Epoch 6/10\n",
            "1250/1250 [==============================] - 19s 15ms/step - loss: 0.7147 - accuracy: 0.7566 - val_loss: 0.8037 - val_accuracy: 0.7345\n",
            "Epoch 7/10\n",
            "1250/1250 [==============================] - 19s 15ms/step - loss: 0.6562 - accuracy: 0.7796 - val_loss: 0.6737 - val_accuracy: 0.7678\n",
            "Epoch 8/10\n",
            "1250/1250 [==============================] - 19s 15ms/step - loss: 0.6101 - accuracy: 0.7926 - val_loss: 0.7764 - val_accuracy: 0.7396\n",
            "Epoch 9/10\n",
            "1250/1250 [==============================] - 19s 15ms/step - loss: 0.5702 - accuracy: 0.8077 - val_loss: 0.6876 - val_accuracy: 0.7641\n",
            "Epoch 10/10\n",
            "1250/1250 [==============================] - 19s 15ms/step - loss: 0.5342 - accuracy: 0.8173 - val_loss: 0.7385 - val_accuracy: 0.7622\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Trial ID: 5d831b02e212f925b67b8ab0d17c5fdd</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Score: 0.767799973487854</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Best step: 0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-conv_1_filter: 80</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:blue\"> |-conv_1_kernel: 4</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-conv_2_filter: 48</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:blue\"> |-conv_2_kernel: 4</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-conv_3_filter: 64</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:blue\"> |-conv_3_kernel: 4</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-conv_4_filter: 32</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:blue\"> |-conv_4_kernel: 4</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-conv_5_filter: 64</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:blue\"> |-conv_5_kernel: 3</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-conv_6_filter: 64</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:blue\"> |-conv_6_kernel: 4</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-dense_1_units: 144</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:blue\"> |-learning_rate: 0.01</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 1.6148 - accuracy: 0.4171 - val_loss: 1.6299 - val_accuracy: 0.4255\n",
            "Epoch 2/10\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 1.1291 - accuracy: 0.5999 - val_loss: 1.2776 - val_accuracy: 0.5922\n",
            "Epoch 3/10\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 0.9427 - accuracy: 0.6762 - val_loss: 0.9400 - val_accuracy: 0.6759\n",
            "Epoch 4/10\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 0.8268 - accuracy: 0.7184 - val_loss: 0.7464 - val_accuracy: 0.7448\n",
            "Epoch 5/10\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 0.7422 - accuracy: 0.7478 - val_loss: 0.7326 - val_accuracy: 0.7495\n",
            "Epoch 6/10\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 0.6806 - accuracy: 0.7702 - val_loss: 0.8764 - val_accuracy: 0.7183\n",
            "Epoch 7/10\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 0.6208 - accuracy: 0.7908 - val_loss: 0.7611 - val_accuracy: 0.7563\n",
            "Epoch 8/10\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 0.5709 - accuracy: 0.8080 - val_loss: 0.6482 - val_accuracy: 0.7839\n",
            "Epoch 9/10\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 0.5232 - accuracy: 0.8245 - val_loss: 0.6571 - val_accuracy: 0.7833\n",
            "Epoch 10/10\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 0.4889 - accuracy: 0.8367 - val_loss: 0.6545 - val_accuracy: 0.7835\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Trial ID: 8ab3ea71df1f5c6fd1d0427c74ddec84</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Score: 0.7839000225067139</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Best step: 0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-conv_1_filter: 64</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:blue\"> |-conv_1_kernel: 3</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-conv_2_filter: 32</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:blue\"> |-conv_2_kernel: 3</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-conv_3_filter: 48</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:blue\"> |-conv_3_kernel: 4</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-conv_4_filter: 48</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:blue\"> |-conv_4_kernel: 4</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-conv_5_filter: 64</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:blue\"> |-conv_5_kernel: 4</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-conv_6_filter: 48</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:blue\"> |-conv_6_kernel: 4</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-dense_1_units: 112</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:blue\"> |-learning_rate: 0.01</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Oracle triggered exit\n",
            "Selecting the best model from the trail\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 32, 32, 64)        1792      \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 32, 32, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 32, 32, 32)        18464     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 16, 16, 48)        24624     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 16, 16, 48)        192       \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 16, 16, 48)        36912     \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 16, 16, 48)        192       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 48)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 8, 8, 64)          49216     \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 8, 8, 64)          256       \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 8, 8, 48)          49200     \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 8, 8, 48)          192       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 48)          0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 4, 4, 48)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 768)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 112)               86128     \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 112)               448       \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 112)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                1130      \n",
            "=================================================================\n",
            "Total params: 269,130\n",
            "Trainable params: 268,298\n",
            "Non-trainable params: 832\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "417/417 [==============================] - 7s 18ms/step - loss: 0.3636 - accuracy: 0.8773 - val_loss: 0.6023 - val_accuracy: 0.8110\n",
            "Epoch 2/20\n",
            "417/417 [==============================] - 7s 17ms/step - loss: 0.3075 - accuracy: 0.8962 - val_loss: 0.6005 - val_accuracy: 0.8105\n",
            "Epoch 3/20\n",
            "417/417 [==============================] - 7s 17ms/step - loss: 0.2771 - accuracy: 0.9047 - val_loss: 0.6134 - val_accuracy: 0.8170\n",
            "Epoch 4/20\n",
            "417/417 [==============================] - 7s 17ms/step - loss: 0.2613 - accuracy: 0.9091 - val_loss: 0.7604 - val_accuracy: 0.7828\n",
            "Index(['loss', 'accuracy', 'val_loss', 'val_accuracy'], dtype='object')\n",
            "Training loss vs Validation loss\n",
            "\n",
            "\n",
            "Index(['loss', 'accuracy', 'val_loss', 'val_accuracy'], dtype='object')\n",
            "\n",
            "\n",
            "Training loss vs Validation loss\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Test Accuracy 0.7842000126838684\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AsI-3a6OF4nc"
      },
      "source": [
        "Part 2: Describe What you did (50% of grade)\n",
        "All the work you did leading up to your final model from Part 1 should be summarized in this section. This should be a logical and well-organized summary of the various experiments that were tried in Part 1. You should write an explanation of what you did and how you made decisions. Upon reading this section I should understand the reasoning that lead you to your final model. All references should be included in the noted section below.\n",
        "\n",
        "See this guide for how to format markdown cells in Jupyter notebooks. For instance, it may be convenient to report your results in table format.\n",
        "\n",
        "Type Markdown and LaTeX: 2\n",
        "References\n",
        "Please include all references used in completing this lab: books, tutorials, blogs, github, etc.\n",
        "\n",
        "Reference details and link: \n",
        "Reference details and link: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTjha0flGFq_"
      },
      "source": [
        "**Step1:** Importing required libraries and  installing keras tuner\n",
        "\n",
        "**Step2:** Splitting the CIFAR10 data in required rows for traning, test and validation splits\n",
        "\n",
        "**Step 3:** Dividing data(X) by 255 to scale the data to a standard format within range of 0 to 1\n",
        "And convert the labels(y) to categorical values from 0 to 9 where each number denotes a one hot encoded specific class\n",
        "\n",
        "**Step 4:** The designed CNN model contains the following blocks structurally\n",
        "\n",
        "1.  6 convolution layers - Each has below sub filters from keras tuner\n",
        "\n",
        "> \n",
        "\n",
        "*   **Keras tuner filter selector** to select number of filters from the range of (32-64) by doing iteration\n",
        "*   **Keras tuner filter_size** To selects best filter size to be used for that particular convolutional layer by selecting kernel size (between 3,4) \n",
        "*   'RELU' Activation function\n",
        "*   Padding = 'same': Implements padding surrounding the image\n",
        "*   Batch Normalization- To normalize the output of a convolution layer's mean values close to zero and standard deviation within 1 to avoid large differences in output parameters\n",
        "*   Max Pool layer after every 2 convolutional layers of pool size 2 (total of 3 in the network)\n",
        "*   One Drop out layer of 0.2  to randomly drop 20% of neurons in the applied layer .\n",
        "\n",
        "2.   One Fully Connected Neural Network\n",
        "\n",
        "*   **Keras tuner  Neuron selector** to select best number of neurons in range of 64 to 256\n",
        "*   'RELU' Activation function\n",
        "*   Batch Normalization \n",
        "*   One Drop out layer of 0.5(to randomly drop 50% of neurons in the applied layer) at the last convolution layer\n",
        "*   second dense layer of 10 neurons\n",
        "*   'softmax' activation\n",
        "\n",
        "3.   Compile\n",
        "\n",
        "*   **keras tuner learning rate selector** to select learning rate between 0.001 and 0.003\n",
        "*   Loss = categorical_crossentropy to deal with one hot encoded  2 dimentional Image labels which are mutually exclusive in nature. \n",
        "*   Metrics = accuracy this is used to monitor train accuracy\n",
        "\n",
        "**Keras Tuner ** - We have implemented Keras Tuner for tuning hyperParameter such as number of filter, filter size, Number of neurons in dense layer and learning rate of optimizer to gain best validation Accuracy.For that we built one function named build_model.\n",
        "\n",
        "\n",
        "**Step 5:** Best hyper parameters selection using Random search function in keras tuner.This Function is used to execute our modelfunction\n",
        "*   This step uses as predefined function function \"RandomSearch\" with parameters.This function performs the iteration loop, which evaluates a certain number of hyperparameter combinations as output\n",
        "\n",
        "1.   Model which is referred/chosen to predict( model_built function above in step 4)\n",
        "2.   objective; 'val_accuracy' ( validation accuracy is parameter of examination)\n",
        "3. Max trails: number of trails to carry out this random search validation\n",
        "4. directory : temporary allocation of code block to store the results\n",
        "5. project_name : Name of the project\n",
        "\n",
        "**Step 6:**Upon above function execution derive parameters for the network to acheive best performance and assign the model to the variable\n",
        "\n",
        "**Step 7:**fit the model to the data enabling early stopping\n",
        "\n",
        "*  Early Stopping: Functionality to observe saturation of learning by the model on the data and stop at the best validation and traning accuracy\n",
        "\n",
        "**Step 8:**Demographics and plots\n",
        "\n",
        "*   Derive list of accuracies and loss for traning and validation acquired from above fit's epochs.\n",
        "*   derive line plot for losses and accuracies for traning and validation data\n",
        "\n",
        "**Step 9:**Test Data Accuracy\n",
        "\n",
        "*  Evaluate the model accuracy for Test Data \n",
        "\n",
        "**Achieved a validation accuracy of 81.09% and test accuracy of 80%**\n",
        "\n",
        "**Reference Links:**\n",
        "https://machinelearningmastery.com/how-to-develop-a-cnn-from-scratch-for-cifar-10-photo-classification/\n",
        "\n",
        "https://www.sicara.ai/blog/hyperparameter-tuning-keras-tuner\n",
        "\n",
        "**Project By**\n",
        "Siddhesh Dwarkanath Munagekar: 0747944,\n",
        "Chaitanya Dutt M V : 0749773 ,\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "   \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "           "
      ]
    }
  ]
}